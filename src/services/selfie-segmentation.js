/*
AI usage disclosure: 

Around 70% of the code in this file is written with AI assistance,
especially the parts involving overlay effect implementation, blur mask creation.

JSDoc annotations are generated by GitHub Copilot and reviewed/modified by human.

*/
import { FilesetResolver, ImageSegmenter } from "@mediapipe/tasks-vision";

const DEFAULT_MODEL =
	"https://storage.googleapis.com/mediapipe-models/image_segmenter/selfie_segmenter/float16/latest/selfie_segmenter.tflite";
const DEFAULT_WASM =
	"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm";

export class SelfieSegmentation {
	constructor() {
		this.segmenter = null;
		this.mode = null;
		this.isRunning = false; // Loop
		this.video = null;
		this.canvas = null;
		this.ctx = null;
		this.rafId = null;
		this.lastVideoTime = -1;
		this.overlayMode = "none"; // 'none' | 'high-contrast'
		this.blurEnabled = false;
		this._latestBlurCanvas = null;
		this.interval = 0.15; // Default interval in seconds

		// Processing canvas for resizing input
		this.processingWidth = 256;
		this.processingHeight = 256;
		this.processingCanvas = null;
		this.processingCtx = null;

		// Blur/mask params
		this.blurDownscale = 0.25;
		this.blurSmallRadiusPx = 2;
		this.maskThreshold = 0.5;
		this.maskSmooth = 0.1;

		// Offscreen canvas; the displayed one is this.canvas
		this.layers = {
			mask: { small: null, full: null }, // 256x256 and full-res (scaled from 256)
			bg: { small: null, blur: null, full: null },
			fg: { full: null },
			out: { latest: null },
		};
		this._boundLoop = this.loop.bind(this);
	}

	/**
	 * Initialize the image segmenter
	 * @param {Object} options - Configuration options
	 */
	async init(options = {}) {
		if (this.segmenter) {
			return this.segmenter;
		}

		// Initialize processing canvas
		this.processingCanvas = document.createElement("canvas");
		this.processingCanvas.width = this.processingWidth;
		this.processingCanvas.height = this.processingHeight;
		this.processingCtx = this.processingCanvas.getContext("2d", {
			willReadFrequently: true,
		});

		this.mode = options.runningMode ?? "VIDEO";
		const vision = await FilesetResolver.forVisionTasks(
			options.wasmPath ?? DEFAULT_WASM,
		);

		this.segmenter = await ImageSegmenter.createFromOptions(vision, {
			baseOptions: {
				modelAssetPath: options.modelAssetPath ?? DEFAULT_MODEL,
				delegate: options.delegate ?? "GPU",
			},
			runningMode: this.mode,
			outputCategoryMask: false,
			outputConfidenceMasks: true,
		});

		return this.segmenter;
	}

	/**
	 * Start segmentation loop
	 * @param {HTMLVideoElement} video
	 * @param {HTMLCanvasElement} canvas
	 * @param {number} interval - Update interval in seconds
	 */
	start(video, canvas, interval = 0.1) {
		if (!this.segmenter) {
			console.error("Segmenter not initialized");
			return;
		}
		this.video = video;
		this.canvas = canvas;
		this.ctx = this.canvas.getContext("2d");
		this.interval = interval;
		this.isRunning = true;
		this.lastVideoTime = -1;

		if (this.video.requestVideoFrameCallback) {
			this.rafId = this.video.requestVideoFrameCallback(this._boundLoop);
		} else {
			this.rafId = requestAnimationFrame(this._boundLoop);
		}
	}

	/**
	 * Stop segmentation loop
	 */
	stop() {
		this.isRunning = false;
		if (this.rafId) {
			if (this.video?.cancelVideoFrameCallback) {
				this.video.cancelVideoFrameCallback(this.rafId);
			} else {
				cancelAnimationFrame(this.rafId);
			}
			this.rafId = null;
		}
		this.lastVideoTime = -1;
		// Clear canvas
		if (this.canvas && this.ctx) {
			this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
		}
	}

	/**
	 * Enable/disable background blur capture
	 * @param {boolean} enable
	 */
	enableBlur(enable) {
		this.blurEnabled = !!enable;
	}

	/**
	 * Set preview overlay mode ('none' | 'high-contrast')
	 * @param {string} mode
	 */
	setOverlay(mode) {
		this.overlayMode = mode === "high-contrast" ? "high-contrast" : "none";
	}

	/**
	 * Returns whether blur is enabled
	 */
	isBlurEnabled() {
		return this.blurEnabled;
	}

	/**
	 * Latest composited canvas (null until blur is restored)
	 * @returns {HTMLCanvasElement|null}
	 */
	getLatestBlurCanvas() {
		return this.blurEnabled ? this._latestBlurCanvas : null;
	}

	/**
	 * Main segmentation loop
	 * @param {DOMHighResTimeStamp} _now
	 * @param {VideoFrameCallbackMetadata} _metadata
	 */
	loop(_now, _metadata) {
		if (!this.isRunning || !this.video) return;

		// Check if video is ready and playing
		if (this.video.readyState < 2 || this.video.paused || this.video.ended) {
			this._scheduleNextLoop();
			return;
		}

		const currentTime = this.video.currentTime;
		if (
			this.lastVideoTime < 0 || // First frame always runs
			currentTime - this.lastVideoTime >= this.interval
		) {
			this.lastVideoTime = currentTime;
			const startTimeMs = performance.now();

			if (this.segmenter) {
				// Draw video to processing canvas
				this.processingCtx.drawImage(
					this.video,
					0,
					0,
					this.processingWidth,
					this.processingHeight,
				);

				const result = this.segmenter.segmentForVideo(
					this.processingCanvas,
					startTimeMs,
				);
				this.draw(result);
			}
		}

		this._scheduleNextLoop();
	}

	/**
	 * Create and return a 2D context; canvas accessible via ctx.canvas
	 * @param {number} w - Canvas width
	 * @param {number} h - Canvas height
	 * @param {Object} ctxOptions - Context options
	 * @returns {CanvasRenderingContext2D} 2D rendering context
	 * @private
	 */
	_makeLayer(w, h, ctxOptions) {
		const canvas = document.createElement("canvas");
		canvas.width = w;
		canvas.height = h;
		return canvas.getContext("2d", ctxOptions || undefined);
	}

	/**
	 * Ensure a context exists at given size (creates if null or resizes if needed)
	 * @param {CanvasRenderingContext2D|null} ctx - Existing context or null
	 * @param {number} w - Desired canvas width
	 * @param {number} h - Desired canvas height
	 * @param {Object} ctxOptions - Context options for creation
	 * @returns {CanvasRenderingContext2D} The context at the specified size
	 * @private
	 */
	_ensureLayer(ctx, w, h, ctxOptions) {
		if (!ctx) return this._makeLayer(w, h, ctxOptions);
		const c = ctx.canvas;
		if (c.width !== w || c.height !== h) {
			c.width = w;
			c.height = h;
		}
		return ctx;
	}

	/**
	 * Ensure all offscreen layers are created and sized correctly for current video dimensions
	 * @param {number} videoW - Video width
	 * @param {number} videoH - Video height
	 * @private
	 */
	_ensureOffscreens(videoW, videoH) {
		const { mask, bg, fg, out } = this.layers;

		// Ensure(create) 256x256 and full-res mask layers
		this.layers.mask.small = this._ensureLayer(
			mask.small,
			this.processingWidth,
			this.processingHeight,
			{ willReadFrequently: true },
		);
		this.layers.mask.full = this._ensureLayer(mask.full, videoW, videoH);

		// Low-res sizes
		const sw = Math.max(1, Math.floor(videoW * this.blurDownscale)); // At least 1px
		const sh = Math.max(1, Math.floor(videoH * this.blurDownscale));

		// Ensure(create) bg layers
		this.layers.bg.small = this._ensureLayer(bg.small, sw, sh);
		this.layers.bg.blur = this._ensureLayer(bg.blur, sw, sh);
		this.layers.bg.full = this._ensureLayer(bg.full, videoW, videoH);

		// Ensure(create) fg and output layers
		this.layers.fg.full = this._ensureLayer(fg.full, videoW, videoH);
		this.layers.out.latest = this._ensureLayer(out.latest, videoW, videoH);

		// Add for easy access
		this._latestBlurCanvas = this.layers.out.latest.canvas;
	}

	/**
	 * Build 256x256 alpha mask with feathering and write to layers.mask.small
	 * @param {Float32Array} maskData - Raw mask data from segmenter (0.0 to 1.0)
	 * @private
	 */
	_writeMask256(maskData) {
		const w = this.processingWidth;
		const h = this.processingHeight;
		const ctx = this.layers.mask.small;
		const img = ctx.createImageData(w, h);

		const t0 = this.maskThreshold - this.maskSmooth;
		const t1 = this.maskThreshold + this.maskSmooth;
		const inv = 1 / Math.max(1e-6, t1 - t0); // Feathering inverse factor

		for (let i = 0, n = w * h; i < n; i++) {
			let a = (maskData[i] - t0) * inv; // Normalize to 0..1
			if (a < 0) a = 0;
			else if (a > 1) a = 1;
			const off = i * 4;
			img.data[off] = 0;
			img.data[off + 1] = 0;
			img.data[off + 2] = 0;
			img.data[off + 3] = (a * 255) | 0;
		}
		ctx.putImageData(img, 0, 0);
	}

	/**
	 * Update blurred composite into layers.out.latest (blurred background + sharp person)
	 * @param {Float32Array} maskData - Segmentation mask data
	 * @param {number} videoW - Video width
	 * @param {number} videoH - Video height
	 * @private
	 */
	_updateBlurComposite(maskData, videoW, videoH) {
		const { mask, bg, fg, out } = this.layers;
		this._ensureOffscreens(videoW, videoH);

		// Upscale mask to full-res
		this._writeMask256(maskData);
		const mFullCtx = mask.full;
		mFullCtx.save();
		mFullCtx.clearRect(0, 0, videoW, videoH);
		mFullCtx.imageSmoothingEnabled = true;
		mFullCtx.imageSmoothingQuality = "high";
		mFullCtx.drawImage(
			mask.small.canvas,
			0,
			0,
			this.processingWidth,
			this.processingHeight,
			0,
			0,
			videoW,
			videoH,
		);
		mFullCtx.restore();

		// Get low-res background for blurring
		const sw = bg.small.canvas.width;
		const sh = bg.small.canvas.height;

		bg.small.save();
		bg.small.clearRect(0, 0, sw, sh);
		bg.small.imageSmoothingEnabled = true;
		bg.small.imageSmoothingQuality = "low";
		bg.small.drawImage(this.video, 0, 0, sw, sh);
		bg.small.restore();

		// Get blurred background
		bg.blur.save();
		bg.blur.clearRect(0, 0, sw, sh);
		bg.blur.filter = `blur(${this.blurSmallRadiusPx}px)`;
		bg.blur.drawImage(bg.small.canvas, 0, 0, sw, sh);
		bg.blur.filter = "none";
		bg.blur.restore();

		// Upscale to full-res with mask cutout
		bg.full.save();
		bg.full.clearRect(0, 0, videoW, videoH);
		bg.full.imageSmoothingEnabled = true;
		bg.full.imageSmoothingQuality = "low";
		bg.full.drawImage(bg.blur.canvas, 0, 0, sw, sh, 0, 0, videoW, videoH);
		bg.full.globalCompositeOperation = "destination-out"; // to cut out person
		bg.full.drawImage(mask.full.canvas, 0, 0, videoW, videoH);
		bg.full.globalCompositeOperation = "source-over"; // reset
		bg.full.restore();

		// Get foreground (person) cutout
		fg.full.save();
		fg.full.clearRect(0, 0, videoW, videoH);
		fg.full.drawImage(this.video, 0, 0, videoW, videoH);
		fg.full.globalCompositeOperation = "destination-in"; // keep only person
		fg.full.drawImage(mask.full.canvas, 0, 0, videoW, videoH);
		fg.full.globalCompositeOperation = "source-over";
		fg.full.restore();

		// Composite into latest
		const outCtx = out.latest;
		outCtx.save();
		outCtx.clearRect(0, 0, videoW, videoH);
		outCtx.drawImage(bg.full.canvas, 0, 0);
		outCtx.drawImage(fg.full.canvas, 0, 0);
		outCtx.restore();
	}

	/**
	 * Schedule the next loop iteration
	 * @private
	 */
	_scheduleNextLoop() {
		if (!this.isRunning || !this.video) return;
		if (this.video.requestVideoFrameCallback) {
			this.rafId = this.video.requestVideoFrameCallback(this._boundLoop);
		} else {
			this.rafId = requestAnimationFrame(this._boundLoop);
		}
	}

	/**
	 * Draw the segmentation result with overlay effect
	 * @param {ImageSegmenterResult} result
	 */
	draw(result) {
		if (!this.canvas || !this.video || !this.ctx) return;
		const ctx = this.ctx;
		const width = this.video.videoWidth;
		const height = this.video.videoHeight;

		if (!width || !height) return;

		if (this.canvas.width !== width || this.canvas.height !== height) {
			this.canvas.width = width;
			this.canvas.height = height;
		}

		const mask = this._selectPrimaryMask(result);
		try {
			if (!mask) {
				ctx.drawImage(this.video, 0, 0, width, height);
				this._latestBlurCanvas = null;
				return;
			}

			// Draw video to processing canvas
			this.processingCtx.drawImage(
				this.video,
				0,
				0,
				this.processingWidth,
				this.processingHeight,
			);

			// Decide if blur needed
			if (this.blurEnabled) {
				const maskData = mask.getAsFloat32Array();
				this._updateBlurComposite(maskData, width, height);
			} else {
				this._latestBlurCanvas = null;
			}

			// If the mode is high-contrast, draw that, else draw blur or original
			if (this.overlayMode === "high-contrast") {
				ctx.imageSmoothingEnabled = true;
				this.drawHighContrastOnProcessing(mask);
				ctx.drawImage(
					this.processingCanvas,
					0,
					0,
					this.processingWidth,
					this.processingHeight,
					0,
					0,
					width,
					height,
				);
			} else if (this.blurEnabled && this._latestBlurCanvas) {
				ctx.drawImage(this._latestBlurCanvas, 0, 0, width, height);
			} else {
				ctx.drawImage(this.video, 0, 0, width, height);
			}
		} finally {
			try {
				mask?.close?.();
				result?.close?.();
			} catch (_) {}
		}
	}

	/**
	 * Select the primary mask from segmentation result
	 * @param {ImageSegmenterResult} result - Segmentation result
	 * @returns {SegmentationMask|null} Primary mask or null if none available
	 * @private
	 */
	_selectPrimaryMask(result) {
		const masks = result?.confidenceMasks;
		if (!masks || masks.length === 0) {
			return null;
		}
		return masks.length > 1 ? masks[1] : masks[0];
	}

	/**
	 * Draw high contrast overlay on the processing canvas (256x256)
	 * @param {SegmentationMask} mask
	 */
	drawHighContrastOnProcessing(mask) {
		const ctxSmall = this.processingCtx;
		const w = this.processingWidth;
		const h = this.processingHeight;

		// Get the video data from the processing canvas (already drawn in loop)
		const imageData = ctxSmall.getImageData(0, 0, w, h);
		const pixels = imageData.data;

		// Get mask data as floats (0.0 to 1.0)
		const maskData = mask.getAsFloat32Array();

		const len = w * h;

		// Person Overlay: Gold
		const personR = 255;
		const personG = 215;
		const personB = 0;
		const personAlpha = 0.9;

		// Background Overlay: Black
		const bgR = 0;
		const bgG = 0;
		const bgB = 0;
		const bgAlpha = 1.0;

		for (let i = 0; i < len; ++i) {
			const score = maskData[i]; // 0.0 (background) to 1.0 (person)
			const isPerson = score;
			const isBackground = 1 - score;

			// Interpolate overlay color and alpha based on the mask score
			const targetR = isPerson * personR + isBackground * bgR;
			const targetG = isPerson * personG + isBackground * bgG;
			const targetB = isPerson * personB + isBackground * bgB;
			const targetAlpha = isPerson * personAlpha + isBackground * bgAlpha;

			const offset = i * 4;

			const srcR = pixels[offset];
			const srcG = pixels[offset + 1];
			const srcB = pixels[offset + 2];

			// Apply blending
			pixels[offset] = srcR * (1 - targetAlpha) + targetR * targetAlpha; // R
			pixels[offset + 1] = srcG * (1 - targetAlpha) + targetG * targetAlpha; // G
			pixels[offset + 2] = srcB * (1 - targetAlpha) + targetB * targetAlpha; // B
		}

		ctxSmall.putImageData(imageData, 0, 0);
	}

	/**
	 * Dispose the segmenter and free resources
	 */
	dispose() {
		this.stop();
		if (this.segmenter) {
			this.segmenter.close();
			this.segmenter = null;
		}
		this._latestBlurCanvas = null;
	}
}
